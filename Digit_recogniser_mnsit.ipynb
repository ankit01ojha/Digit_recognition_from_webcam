{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train = pd.read_csv('datasets/train.csv')\n",
    "    #test =  testimg\n",
    "    y_train = train['label']\n",
    "    x_train = train.drop(labels = ['label'], axis =1)\n",
    "    \n",
    "     #Normalising the data\n",
    "    x_train = x_train/255.0\n",
    "    x_train = x_train.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    #test = test/255.0\n",
    "    #test = test.values.reshape(-1,28,28,1)\n",
    "    \n",
    "    #coverting y to one-hot \n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    \n",
    "    x_train, x_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3) , activation = 'relu', input_shape = (28,28,1)))\n",
    "    model.add(layers.MaxPooling2D(3,3))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation = 'softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "    history = model.fit(x_train, Y_train, epochs =10, batch_size=128, validation_data = (x_val, Y_val), verbose=2)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testimg,model):\n",
    "    test = testimg/255.0\n",
    "    test = test.reshape(-1,28,28,1)\n",
    "    results = model.predict(test)\n",
    "    results = np.argmax(results, axis=1)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return img, contours, thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 65,354\n",
      "Trainable params: 65,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      " - 15s - loss: 0.9047 - acc: 0.6915 - val_loss: 0.1891 - val_acc: 0.9483\n",
      "Epoch 2/10\n",
      " - 14s - loss: 0.2839 - acc: 0.9126 - val_loss: 0.1201 - val_acc: 0.9607\n",
      "Epoch 3/10\n",
      " - 14s - loss: 0.2186 - acc: 0.9348 - val_loss: 0.0933 - val_acc: 0.9695\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.1843 - acc: 0.9444 - val_loss: 0.0783 - val_acc: 0.9729\n",
      "Epoch 5/10\n",
      " - 14s - loss: 0.1579 - acc: 0.9528 - val_loss: 0.0749 - val_acc: 0.9750\n",
      "Epoch 6/10\n",
      " - 15s - loss: 0.1371 - acc: 0.9587 - val_loss: 0.0623 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      " - 14s - loss: 0.1256 - acc: 0.9618 - val_loss: 0.0570 - val_acc: 0.9824\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.1131 - acc: 0.9663 - val_loss: 0.0566 - val_acc: 0.9829\n",
      "Epoch 9/10\n",
      " - 14s - loss: 0.1138 - acc: 0.9665 - val_loss: 0.0501 - val_acc: 0.9845\n",
      "Epoch 10/10\n",
      " - 14s - loss: 0.1033 - acc: 0.9694 - val_loss: 0.0474 - val_acc: 0.9852\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "model = main()\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img, contours, thresh = get_img_contour_thresh(img)\n",
    "    ans1 = ''\n",
    "    if len(contours) > 0:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(contour) > 2500:\n",
    "            # print(predict(w_from_model,b_from_model,contour))\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # newImage = thresh[y - 15:y + h + 15, x - 15:x + w +15]\n",
    "            newImage = thresh[y:y + h, x:x + w]\n",
    "            newImage = cv2.resize(newImage, (28, 28))\n",
    "            newImage = np.array(newImage)\n",
    "            newImage = newImage.flatten()\n",
    "            newImage = newImage.reshape(newImage.shape[0], 1)\n",
    "            ans1 = predict(newImage,model)\n",
    "\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.putText(img, \"Result : \" + str(ans1), (10, 320),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    cv2.imshow(\"Contours\", thresh)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
